{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For off-target insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "figsuplix = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_Exist_file(path):\n",
    "    import os\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    import os\n",
    "    path = path.strip()  # 去除首位空格\n",
    "    path = path.rstrip(\"\\\\\")  # 去除尾部 \\ 符号\n",
    "    isExists = os.path.exists(path)  # 判断路径是否存在\n",
    "    # 判断结果\n",
    "    if not isExists:\n",
    "        os.makedirs(path)  # 如果不存在则创建目录\n",
    "        print(path + ' 创建成功')\n",
    "    else:\n",
    "        print(path + ' 目录已存在')  # 如果目录存在则不创建，并提示目录已存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mutation 坐标转换\n",
    "#####################################################################################\n",
    "## 反向互补\n",
    "def reverseComplement(seq):\n",
    "    \"\"\"\n",
    "     生成反向互补序列\n",
    "     :param seq:\n",
    "     :return:revComSeq\n",
    "     \"\"\"\n",
    "    ATCG_dict = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', 'a': 't', 't': 'a', 'c': 'g', 'g': 'c', 'N': 'N'}\n",
    "    revComSeq = ''\n",
    "    for i in seq:\n",
    "        revComSeq = ATCG_dict[i] + revComSeq\n",
    "    return revComSeq\n",
    "\n",
    "\n",
    "## 转换核心函数\n",
    "def transformer_core(mut, index_dict):\n",
    "    if 'M' in mut:\n",
    "        inf, sup = int(mut.split(':')[0][1:]), int(mut.split(':')[1][:3])\n",
    "        bn, an = mut.split('_')[1].split(':')[0], mut.split('_')[1].split(':')[1]\n",
    "        new_inf, new_sup = index_dict[inf], index_dict[sup]\n",
    "        new_bn, new_an = reverseComplement(bn), reverseComplement(an)\n",
    "        return '%s%s:%sM_%s:%s'%(mut[0], new_inf, new_sup, new_bn, new_an)\n",
    "    elif 'I' in mut:\n",
    "        new_inser_site = index_dict[int(mut.split('_')[0][1:-1])]\n",
    "        new_inser_nucles = reverseComplement(mut.split('_')[-1])\n",
    "        return '%s%sI_%s'%(mut[0], new_inser_site, new_inser_nucles)\n",
    "    elif 'D' in mut:\n",
    "        inf, sup = int(mut.split(':')[0][1:]), int(mut.split(':')[-1][:-1])\n",
    "        new_inf, new_sup = index_dict[inf], index_dict[sup]\n",
    "        return '%s%s:%sD'%(mut[0], new_inf, new_sup)\n",
    "    else:\n",
    "        return mut\n",
    "\n",
    "\n",
    "## 解析 all_mutation & target_mutation 信息\n",
    "def parse_mutation_information(mutation):\n",
    "    '''\n",
    "    mutation = 'X0+Y179:180D.Y186:186M_C:A+Z196I_T'\n",
    "    # mutation = 'X0+Y0+Z0'\n",
    "    muts = parse_mutation_information(mutation)\n",
    "    '''\n",
    "    import re\n",
    "    mut_list = re.split('\\+|\\.', mutation)\n",
    "    mut_dict = {'X': [], 'Y': [], 'Z': []}\n",
    "    for mut in mut_list:\n",
    "        mut_dict[mut[0]].append(mut)\n",
    "    return mut_dict\n",
    "\n",
    "\n",
    "## 调整突变坐标的参考系：以 gRNASeq 为基\n",
    "def adjust_off_target_mutaion_reference_system(mutation):\n",
    "    '''\n",
    "    mutation = 'X164I_T+Y178I_C+Z0'\n",
    "    mutation = 'X164:164D+Y187I_G+Z199:199M_C:T'\n",
    "    mutation = 'X0+Y0+Z0'\n",
    "    adjust_off_target_mutaion_reference_system(mutation)\n",
    "    '''\n",
    "    ## 长序列与短序列对应字典\n",
    "    index_dict = {}\n",
    "    for i in range(20):\n",
    "        index_dict[125 + i] = -19 + i\n",
    "    for i in range(63):\n",
    "        index_dict[145 + i] = 1 + i\n",
    "    for i in range(20):\n",
    "        index_dict[208 + i] = 64 + i\n",
    "    ## 解析 all_mutation & target_mutation 信息\n",
    "    mut_dict = parse_mutation_information(mutation)\n",
    "    new_mut_dict = {'X': '', 'Y': '', 'Z': ''}\n",
    "    for label, mut_list in mut_dict.items():\n",
    "        a_list = []\n",
    "        for mut in mut_list:\n",
    "            new_mut = transformer_core(mut, index_dict)\n",
    "            a_list.append(new_mut)\n",
    "        a_list.sort(reverse=False)\n",
    "        new_mut_dict[label] = '.'.join(a_list)\n",
    "    new_list = []\n",
    "    for label in ['X', 'Y', 'Z']:\n",
    "        new_list.append(new_mut_dict[label])\n",
    "    return '+'.join(new_list)\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## up, core, down 区域内突变核苷酸总长度\n",
    "def region_mutation_length(mutation):\n",
    "    mut_list = mutation.split(\".\")\n",
    "    mut_length = 0\n",
    "    for mut in mut_list:\n",
    "        if 'M' in mut:\n",
    "            mut_length += len(mut.split(\":\")[-1])\n",
    "        elif 'I' in mut:\n",
    "            mut_length += len(mut.split(\"_\")[-1])\n",
    "        elif 'D' in mut:\n",
    "            inf, sup = int(mut.split(':')[0][1:]), int(mut.split(':')[-1][:-1])\n",
    "            delt_length = sup - inf + 1\n",
    "            mut_length += delt_length\n",
    "        else:\n",
    "            pass\n",
    "    return mut_length\n",
    "\n",
    "\n",
    "def mutation_region_splitting(data):\n",
    "    ## step 1: mutaion 区域划分\n",
    "    data['new_mutation'] = data['all_mutation'].apply(lambda x: adjust_off_target_mutaion_reference_system(x))\n",
    "    ## up, core, down 区域内突变类型\n",
    "    data['up_mutation'] = data['new_mutation'].apply(lambda x: x.split('+')[0])\n",
    "    data['core_mutation'] = data['new_mutation'].apply(lambda x: x.split('+')[1])\n",
    "    data['down_mutation'] = data['new_mutation'].apply(lambda x: x.split('+')[2])\n",
    "    ## up, core, down 区域内间断突变的个数\n",
    "    data['up_mut_num'] = data['up_mutation'].apply(lambda x: len(x.split('.')) if x != 'X0' else 0)\n",
    "    data['core_mut_num'] = data['core_mutation'].apply(lambda x: len(x.split('.')) if x != 'Y0' else 0)\n",
    "    data['down_mut_num'] = data['down_mutation'].apply(lambda x: len(x.split('.')) if x != 'Z0' else 0)\n",
    "    ## up, core, down 区域内突变核苷酸总长度\n",
    "    data['up_mut_length'] = data['up_mutation'].apply(lambda x: region_mutation_length(x))\n",
    "    data['core_mut_length'] = data['core_mutation'].apply(lambda x: region_mutation_length(x))\n",
    "    data['down_mut_length'] = data['down_mutation'].apply(lambda x: region_mutation_length(x))\n",
    "    ############################################################\n",
    "    print(\"\\nFirst: 统计 X0+Y0+Z0、XA+Y0+Z0、X0+YA+Z0、X0+Y0+ZA、XA+YA+Z0、XA+Y0+ZA、X0+YA+ZA、XA+YA+ZA 的类型占比\")\n",
    "    data_000 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']==0) & (data['down_mut_num']==0), :]\n",
    "    data_100 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']==0) & (data['down_mut_num']==0), :]\n",
    "    data_010 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']!=0) & (data['down_mut_num']==0), :]\n",
    "    data_001 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']==0) & (data['down_mut_num']!=0), :]\n",
    "    data_110 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']!=0) & (data['down_mut_num']==0), :]\n",
    "    data_101 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']==0) & (data['down_mut_num']!=0), :]\n",
    "    data_011 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']!=0) & (data['down_mut_num']!=0), :]\n",
    "    data_111 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']!=0) & (data['down_mut_num']!=0), :]\n",
    "    ## count\n",
    "    count_dict = {}\n",
    "    count_000 = data_000.shape[0]\n",
    "    count_100, count_010, count_001 = data_100.shape[0], data_010.shape[0], data_001.shape[0]\n",
    "    count_110, count_101, count_011 = data_110.shape[0], data_101.shape[0], data_011.shape[0]\n",
    "    count_111 = data_111.shape[0]\n",
    "    count_dict['X0+Y0+Z0'] = count_000\n",
    "    count_dict['XA+Y0+Z0'] = count_100\n",
    "    count_dict['X0+YA+Z0'] = count_010\n",
    "    count_dict['X0+Y0+ZA'] = count_001\n",
    "    count_dict['XA+YA+Z0'] = count_110\n",
    "    count_dict['XA+Y0+ZA'] = count_101\n",
    "    count_dict['X0+YA+ZA'] = count_011\n",
    "    count_dict['XA+YA+ZA'] = count_111\n",
    "    print(\"X0+Y0+Z0:\", count_000)\n",
    "    print(\"XA+Y0+Z0:\", count_100)\n",
    "    print(\"X0+YA+Z0:\", count_010)\n",
    "    print(\"X0+Y0+ZA:\", count_001)\n",
    "    print(\"XA+YA+Z0:\", count_110)\n",
    "    print(\"XA+Y0+ZA:\", count_101)\n",
    "    print(\"X0+YA+ZA:\", count_011)\n",
    "    print(\"XA+YA+ZA:\", count_111)\n",
    "    count_sum = data.shape[0]\n",
    "    print(\"Distribution of count ratio:\", round(count_000/count_sum, 3), \n",
    "                        round(count_100/count_sum, 3), round(count_010/count_sum, 3), round(count_001/count_sum, 3), \n",
    "                        round(count_110/count_sum, 3), round(count_101/count_sum, 3), round(count_011/count_sum, 3), \n",
    "                        round(count_111/count_sum, 3))\n",
    "    return (data_000, data_100, data_010, data_001, data_110, data_101, data_011, data_111, count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read \n",
    "def get_raw_inser_data(read_dir, mut_type, reads_num, barcode_num):\n",
    "    inser_path = read_dir + '/off-target.%s.accurate.offseq'%(mut_type)\n",
    "    inser = pd.read_csv(inser_path, sep='\\t')\n",
    "    inser = inser.loc[(inser['reads_num']>=reads_num) & (inser['barcode_num']>=barcode_num), :]\n",
    "    inser.reset_index(drop=True, inplace=True)\n",
    "    print('columns:', inser.columns.tolist())\n",
    "    print(inser.shape)\n",
    "    ## data 根据 up, core, down 区域突变与否划分数据集\n",
    "    inser_000, inser_100, inser_010, inser_001, inser_110, inser_101, inser_011, inser_111, count_dict = mutation_region_splitting(inser)\n",
    "    return (inser, inser_000, inser_100, inser_010, inser_001, inser_110, inser_101, inser_011, inser_111)\n",
    "    \n",
    "\n",
    "## read on target \n",
    "def get_on_target_data(read_dir, reads_num=200, barcode_num=10):\n",
    "    data_path = read_dir + '/off-target.perfect.accurate.offseq'\n",
    "    data = pd.read_csv(data_path, sep='\\t')\n",
    "    data = data.loc[(data['reads_num']>=reads_num) & (data['barcode_num']>=barcode_num), :]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    print('columns:', data.columns.tolist())\n",
    "    print(data.shape)\n",
    "    ## data 根据 up, core, down 区域突变与否划分数据集\n",
    "    data_000, data_100, data_010, data_001, data_110, data_101, data_011, data_111, count_dict = mutation_region_splitting(data)\n",
    "    return (data, data_000, data_100, data_010, data_001, data_110, data_101, data_011, data_111)\n",
    "\n",
    "\n",
    "## For insertion & perfect common\n",
    "## 确定 insertion id \n",
    "def obtain_inser_data(inser, data, inser_110, inser_111, data_100, data_101, save_dir):\n",
    "    ## 1、insertion XA+YA+Z0\n",
    "    print(\"\\n1、insertion XA+YA+Z0\")\n",
    "    inser_id_1 = inser_110[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    on_id_1 = data_100[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    comm_id_1 = pd.merge(inser_id_1, on_id_1, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    print(\"XA+YA+Z0 insertion id:\", inser_id_1.shape)\n",
    "    print(\"XA+Y0+Z0 perfect id:\", on_id_1.shape)\n",
    "    print(\"common XA+Y0+Z0 id perfeat id:\", comm_id_1.shape)\n",
    "\n",
    "    ## 2、insertion XA+YA+ZA\n",
    "    print(\"\\n2、insertion XA+YA+ZA\")\n",
    "    inser_id_2 = inser_111[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    on_id_2 = data_101[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    comm_id_2 = pd.merge(inser_id_2, on_id_2, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    print(\"XA+YA+ZA insertion id:\", inser_id_2.shape)\n",
    "    print(\"XA+Y0+ZA perfect id:\", on_id_2.shape)\n",
    "    print(\"common XA+YA+ZA insertion id:\", comm_id_2.shape)\n",
    "\n",
    "    ## merging\n",
    "    print('\\nmerging')\n",
    "    comm_id = pd.concat([comm_id_1, comm_id_2], axis=0)\n",
    "    ## For perfect\n",
    "    on_id = pd.merge(data[['sgRNA_name', 'up_mutation', 'down_mutation', 'reads_num', 'barcode_num', 'off-target_eff']], \n",
    "                     comm_id, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    on_id.rename(columns={'reads_num': 'p_reads_num', 'barcode_num': 'p_barcode_num', 'off-target_eff': 'on-target_eff'}, \n",
    "                 inplace=True)\n",
    "    print(\"perfect on_id:\", on_id.shape)\n",
    "    inser_id = pd.merge(inser, on_id, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    print(\"inser_id.shape:\", inser_id.shape)\n",
    "    ## to save\n",
    "    mkdir(save_dir)\n",
    "    inser_id.to_excel(save_dir + '/off-target insertion data.xlsx', index=False)\n",
    "    return inser_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The distribution of insertion position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "figsuplix = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_Exist_file(path):\n",
    "    import os\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    import os\n",
    "    path = path.strip()  # 去除首位空格\n",
    "    path = path.rstrip(\"\\\\\")  # 去除尾部 \\ 符号\n",
    "    isExists = os.path.exists(path)  # 判断路径是否存在\n",
    "    # 判断结果\n",
    "    if not isExists:\n",
    "        os.makedirs(path)  # 如果不存在则创建目录\n",
    "        print(path + ' 创建成功')\n",
    "    else:\n",
    "        print(path + ' 目录已存在')  # 如果目录存在则不创建，并提示目录已存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for insertion XA+YA+Z0 analysis\n",
    "def insertion_position(mutation):\n",
    "    import re\n",
    "    mut_list = re.split('\\+|\\.', mutation)\n",
    "    positions = []\n",
    "    for mut in mut_list:\n",
    "        if 'I' in mut:\n",
    "            positions.append(int(mut.split(\"_\")[0][1:-1]))\n",
    "        else:\n",
    "            pass\n",
    "    return str(tuple(positions))\n",
    "\n",
    "\n",
    "def insertion_nucleotide(mutation):\n",
    "    import re\n",
    "    mut_list = re.split('\\+|\\.', mutation)\n",
    "    inser_nucle = ''\n",
    "    for mut in mut_list:\n",
    "        if 'I' in mut:\n",
    "            inser_nucle = inser_nucle + mut.split(\"_\")[1]\n",
    "        else:\n",
    "            pass\n",
    "    return inser_nucle\n",
    "\n",
    "\n",
    "def helper_inser_nucle_count(inser_nucle_dict, nucle):\n",
    "    try:\n",
    "        return inser_nucle_dict[nucle]\n",
    "    except KeyError as e:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "\n",
    "## 分析 XA+YA+Z0 中 YA insertion 的长度均是 1\n",
    "## 具体内容：\n",
    "## 1、insertion length distribution\n",
    "## 2、insertion position-count distribution\n",
    "## 3、insertion nucleotide-count distribution\n",
    "## 4、insertion position-nucleotied-count distribution \n",
    "def insertion_count_nucleotide_distribution(inser_id):\n",
    "    inser1 = inser_id.loc[(inser_id['up_mut_num']!=0) & (inser_id['core_mut_num']!=0) & (inser_id['down_mut_num']==0), :]\n",
    "    print(\"insertion XA+YA+Z0 shape:\", inser1.shape)\n",
    "    print(\"inser1['core_mut_length'].value_counts():\", inser1['core_mut_length'].value_counts())\n",
    "    inser1['position'] = inser1['core_mutation'].apply(lambda x: insertion_position(x))\n",
    "    inser1['inser_nucleotide'] = inser1['core_mutation'].apply(lambda x: insertion_nucleotide(x))\n",
    "    print(len(list(inser1['position'].unique())))\n",
    "    print(\"inser_nucleotide.value_counts():\\n\", inser1['inser_nucleotide'].value_counts())\n",
    "\n",
    "    ## insertion position-count distribution \n",
    "    ## insertion position-nucleotide-count distribution\n",
    "    inser_nucle_list = []\n",
    "    inser_length_dict = {}\n",
    "    inser_nucle_dict = {}\n",
    "    for index, row in inser1.iterrows():\n",
    "        pos = eval(row['position'])[0]\n",
    "        nucle = row['inser_nucleotide']\n",
    "        if pos not in inser_length_dict:\n",
    "            inser_length_dict[pos] = 1\n",
    "            inser_nucle_dict[pos] = {nucle: 1}\n",
    "        else:\n",
    "            inser_length_dict[pos] += 1\n",
    "            try:\n",
    "                inser_nucle_dict[pos][nucle] += 1\n",
    "            except KeyError as e:\n",
    "                inser_nucle_dict[pos][nucle] = 1\n",
    "        inser_nucle_list = list(set(inser_nucle_list + [nucle]))\n",
    "    inser_nucle_list.sort(reverse=False)\n",
    "    ## \n",
    "    all_pos = list(inser_length_dict.keys())\n",
    "    all_pos.sort(reverse=False)\n",
    "    pos_df = pd.DataFrame({\"position\": all_pos})\n",
    "    pos_df['inser_count'] = pos_df['position'].apply(lambda x: inser_length_dict[x])\n",
    "    pos_df['inser_nucles'] = pos_df['position'].apply(lambda x: inser_nucle_dict[x])\n",
    "    for nucle in inser_nucle_list:\n",
    "        pos_df[nucle] = pos_df['inser_nucles'].apply(lambda x: helper_inser_nucle_count(x, nucle))\n",
    "    return pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## labels\n",
    "def get_xticks(pos_df):\n",
    "    pam_dict = {41: 'N', 42: 'G', 43: 'G'}\n",
    "    pos_list = pos_df['position'].tolist()\n",
    "    labels = []\n",
    "    for pos in pos_list:\n",
    "        if pos not in pam_dict:\n",
    "            labels.append(pos-20)\n",
    "        else:\n",
    "            labels.append(pam_dict[pos])\n",
    "    return labels\n",
    "\n",
    "\n",
    "## 柱状图\n",
    "def plot_single_bar(data_list, labels, title, save_dir, \n",
    "                    xlabel='Target+PAM Insertion Position', ylabel='Count'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # 设置默认绘图风格\n",
    "    plt.style.use(\"seaborn-white\")  \n",
    "    fig, ax = plt.subplots(1,1, figsize=(12, 4))\n",
    "\n",
    "    plt.bar(range(len(data_list)), data_list, color='darkslateblue')\n",
    "    ## 坐标轴不可见\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ## xlabel, ylabel\n",
    "    plt.xlabel(xlabel, fontsize=12, weight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=12, weight='bold')\n",
    "    ## xticks\n",
    "    plt.xticks(range(len(labels)), labels, fontsize=12, weight='bold')\n",
    "    ## title\n",
    "    plt.title(title, fontsize=12, weight='bold')\n",
    "    ## save\n",
    "    mkdir(save_dir)\n",
    "    savefig_path = save_dir + '/%s.%s'%(title, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "## insertion position nucleotide count distribution\n",
    "def plot_bar(data, xcol, ycol, hue_col, title, save_dir, xticks, xlabel, ylabel, palette):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize=(16, 4))\n",
    "    fig.subplots_adjust(wspace=5)\n",
    "    sns.barplot(x=xcol, y=ycol, hue=hue_col, data=data, palette=palette)\n",
    "    ## 坐标轴不可见\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ## ylim\n",
    "    # plt.ylim(0, 1.1)\n",
    "    plt.ylabel(ylabel, fontsize=12, weight='bold')\n",
    "    plt.xlabel(xlabel, fontsize=12, weight='bold')\n",
    "    ## xticks\n",
    "    plt.xticks(range(len(xticks)), xticks, fontsize=10, weight='bold')\n",
    "    ## title\n",
    "    plt.title(title, fontsize=12, weight='bold')\n",
    "    plt.legend(title='insertion nucleotide')\n",
    "    mkdir(save_dir)\n",
    "    savefig_path = save_dir + '/%s.%s'%(title, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of insertion off-target editing efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for XA+YA+Z0 \n",
    "## positon-insertion nucleotide: relative efficiency\n",
    "def get_insertion_XA_YA_Z0_reltive_efficiency(inser1, on_eff_cutoff=0.05):\n",
    "    ## get relative off-target efficiency\n",
    "    inser1['position'] = inser1['core_mutation'].apply(lambda x: insertion_position(x))\n",
    "    inser1['inser_nucleotide'] = inser1['core_mutation'].apply(lambda x: insertion_nucleotide(x))\n",
    "    inser1 = inser1.loc[inser1['on-target_eff']>=on_eff_cutoff, :]\n",
    "    inser1['reltv_eff'] = inser1.apply(lambda row: row['off-target_eff']/row['on-target_eff'], axis=1)\n",
    "\n",
    "    ## statistic relative efficiency\n",
    "    pos_list = []\n",
    "    nucle_list = []\n",
    "    pos_nucle_eff_dict = {}\n",
    "    inser11 = inser1.loc[inser1['core_mut_num']==1, :]\n",
    "    for index, row in inser11.iterrows():\n",
    "        positions = eval(row['position'])\n",
    "        inser_nucles =  row['inser_nucleotide']\n",
    "        reltv_eff = row['reltv_eff']\n",
    "        for i, nucle in enumerate(inser_nucles):\n",
    "            pos = positions[i]\n",
    "            pos_list.append(pos)\n",
    "            nucle_list.append(nucle)\n",
    "            if pos not in pos_nucle_eff_dict:\n",
    "                pos_nucle_eff_dict[pos] = {nucle: [reltv_eff]}\n",
    "            else:\n",
    "                try:\n",
    "                    pos_nucle_eff_dict[pos][nucle].append(reltv_eff)\n",
    "                except KeyError as e:\n",
    "                    pos_nucle_eff_dict[pos][nucle] = [reltv_eff]\n",
    "    ## DataFrame\n",
    "    pos_list = list(set(pos_list))\n",
    "    pos_list.sort(reverse=False)\n",
    "    nucle_list = list(set(nucle_list))\n",
    "    nucle_list.sort(reverse=False)\n",
    "    stat_df_list = []\n",
    "    for pos in pos_list:\n",
    "        for nucle in nucle_list:\n",
    "            try:\n",
    "                stat_df = pd.DataFrame({'reltv_eff': pos_nucle_eff_dict[pos][nucle]})\n",
    "            except KeyError as e:\n",
    "                stat_df = pd.DataFrame({'reltv_eff': []})\n",
    "            stat_df['position'] = pos\n",
    "            stat_df['inser_nucleotide'] = nucle\n",
    "            stat_df_list.append(stat_df)\n",
    "    stat_df = pd.concat(stat_df_list, axis=0)\n",
    "    stat_df.reset_index(drop=True, inplace=True)\n",
    "    print(\"stat_df.shape:\", stat_df.shape)\n",
    "    return stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the effect of insertion position on editing efficiency\n",
    "def plot_inser_reltv_eff_on_position(stat_df, save_dir):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # 设置默认绘图风格\n",
    "    plt.style.use(\"seaborn-white\")  \n",
    "    fig, ax = plt.subplots(1,1, figsize=(6, 3))\n",
    "\n",
    "    order = [(i) for i in range(24, 44)]\n",
    "    ax = sns.boxplot(x='position', y='reltv_eff', data=stat_df, width=0.4, color='white', \n",
    "                     fliersize=0.5, linewidth=0.5, order=order)\n",
    "    ## 坐标轴不可见\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # # 添加分布散点图 boxplot with jitter\n",
    "    ax = sns.stripplot(x='position', y='reltv_eff', data=stat_df, color=\"orange\", jitter=0.1, \n",
    "                       size=0.8, order=order)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"\")\n",
    "    ## xticks\n",
    "    xticks = list(range(4, 21, 1)) + ['N', 'G', 'G']\n",
    "    print(len(xticks))\n",
    "    plt.xticks(range(20), xticks, fontsize=6, weight='bold')\n",
    "    plt.yticks(fontsize=6, weight='bold')\n",
    "    ## ylim\n",
    "    # plt.ylim(0, 2.3)\n",
    "    plt.xlim(-1, 20)\n",
    "    title = 'Effect of off-target insertion position on gRNA acitvity'\n",
    "    mkdir(save_dir)\n",
    "    savefig_path = save_dir + '/%s.%s'%(title, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## plot: the effect of off-target insertion XA+YA+Z0 nucleotide type on editing efficiency\n",
    "def plot_inser_reltv_eff_on_pos_nucle(stat_df, save_dir):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # 设置默认绘图风格\n",
    "    plt.style.use(\"seaborn-white\")  \n",
    "    fig, ax = plt.subplots(1,1, figsize=(6, 3))\n",
    "\n",
    "    order = [(i) for i in range(24, 44)]\n",
    "    ax = sns.boxplot(x='position', y='reltv_eff', hue='inser_nucleotide', data=stat_df, width=0.6,  \n",
    "                     fliersize=0.5, linewidth=0.5, order=order)\n",
    "    ## 坐标轴不可见\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"\")\n",
    "    ## xticks\n",
    "    xticks = list(range(4, 21, 1)) + ['N', 'G', 'G']\n",
    "    print(len(xticks))\n",
    "    plt.xticks(range(20), xticks, fontsize=6, weight='bold')\n",
    "    plt.yticks(fontsize=6, weight='bold')\n",
    "    ## ylim\n",
    "    plt.xlim(-1, 20)\n",
    "    title = 'Effect of off-target insertion nucleotide type on gRNA activity'\n",
    "    mkdir(save_dir)\n",
    "    savefig_path = save_dir + '/%s.%s'%(title, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot insertion data 分布\n",
    "def plot_distribution_insertion_data(pos_df, data_dir):\n",
    "    ## 1. plot insertion position distribution\n",
    "    # data_list\n",
    "    xticks = get_xticks(pos_df)\n",
    "    data_list = pos_df['inser_count'].tolist()\n",
    "    title = 'position distriburion of off-target insertion'\n",
    "    ylabel = 'off-target id count'\n",
    "    xlabel='Target+PAM Insertion Position'\n",
    "    plot_single_bar(data_list, xticks, title, data_dir, xlabel, ylabel)\n",
    "\n",
    "    ## 2. plot insertion nucleotide distribution without considering insertion position\n",
    "    xticks = ['A', 'C', 'G', 'T']\n",
    "    data_dict = dict(pos_df[xticks].sum(axis=0))\n",
    "    data_list = [data_dict[nucle] for nucle in xticks]\n",
    "    title = 'nucleotide distribution of off-target insertion'\n",
    "    ylabel = 'off-target id count'\n",
    "    xlabel = 'Insertion Nucleotide'\n",
    "    plot_single_bar(data_list, xticks, title, data_dir, xlabel, ylabel)\n",
    "\n",
    "    ## 3. insertion position nucleotide count distribution\n",
    "    xticks = get_xticks(pos_df)\n",
    "    ## plot data\n",
    "    pos_nucle_df_list = []\n",
    "    for col in ['A', 'C', 'G', 'T']:\n",
    "        temp = pos_df[['position', col]]\n",
    "        temp.rename(columns={col: 'count'}, inplace=True)\n",
    "        temp['nucle'] = col\n",
    "        pos_nucle_df_list.append(temp)\n",
    "    pos_nucle_df = pd.concat(pos_nucle_df_list, axis=0)\n",
    "    ## \n",
    "    palette = {'A': 'slateblue', \n",
    "               'C': 'lightseagreen', \n",
    "               'G': 'olive', \n",
    "               'T': 'limegreen', \n",
    "               'Conv2D': 'lightseagreen', \n",
    "               'Conv1D_LSTM': 'deepskyblue', \n",
    "               'Stacked_LSTM': 'royalblue', \n",
    "               'XGBoost': 'slateblue', \n",
    "               'BiLSTM': 'purple'}\n",
    "    xcol = 'position'\n",
    "    ycol = 'count'\n",
    "    hue_col = 'nucle'\n",
    "    xlabel = 'Target+PAM Insertion Position'\n",
    "    ylabel = 'off-target id count'\n",
    "    title = 'position insertion nucleotide distribution of off-target insertion'\n",
    "    plot_bar(pos_nucle_df, xcol, ycol, hue_col, title, data_dir, xticks, xlabel, ylabel, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
