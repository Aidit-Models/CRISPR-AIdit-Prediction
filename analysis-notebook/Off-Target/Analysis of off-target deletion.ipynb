{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For off-target deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "figsuplix = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_Exist_file(path):\n",
    "    import os\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    import os\n",
    "    path = path.strip()  # 去除首位空格\n",
    "    path = path.rstrip(\"\\\\\")  # 去除尾部 \\ 符号\n",
    "    isExists = os.path.exists(path)  # 判断路径是否存在\n",
    "    # 判断结果\n",
    "    if not isExists:\n",
    "        os.makedirs(path)  # 如果不存在则创建目录\n",
    "        print(path + ' 创建成功')\n",
    "    else:\n",
    "        print(path + ' 目录已存在')  # 如果目录存在则不创建，并提示目录已存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mutation 坐标转换\n",
    "#####################################################################################\n",
    "## 反向互补\n",
    "def reverseComplement(seq):\n",
    "    \"\"\"\n",
    "     生成反向互补序列\n",
    "     :param seq:\n",
    "     :return:revComSeq\n",
    "     \"\"\"\n",
    "    ATCG_dict = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', 'a': 't', 't': 'a', 'c': 'g', 'g': 'c', 'N': 'N'}\n",
    "    revComSeq = ''\n",
    "    for i in seq:\n",
    "        revComSeq = ATCG_dict[i] + revComSeq\n",
    "    return revComSeq\n",
    "\n",
    "\n",
    "## 转换核心函数\n",
    "def transformer_core(mut, index_dict):\n",
    "    if 'M' in mut:\n",
    "        inf, sup = int(mut.split(':')[0][1:]), int(mut.split(':')[1][:3])\n",
    "        bn, an = mut.split('_')[1].split(':')[0], mut.split('_')[1].split(':')[1]\n",
    "        new_inf, new_sup = index_dict[inf], index_dict[sup]\n",
    "        new_bn, new_an = reverseComplement(bn), reverseComplement(an)\n",
    "        return '%s%s:%sM_%s:%s'%(mut[0], new_inf, new_sup, new_bn, new_an)\n",
    "    elif 'I' in mut:\n",
    "        new_inser_site = index_dict[int(mut.split('_')[0][1:-1])]\n",
    "        new_inser_nucles = reverseComplement(mut.split('_')[-1])\n",
    "        return '%s%sI_%s'%(mut[0], new_inser_site, new_inser_nucles)\n",
    "    elif 'D' in mut:\n",
    "        inf, sup = int(mut.split(':')[0][1:]), int(mut.split(':')[-1][:-1])\n",
    "        new_inf, new_sup = index_dict[inf], index_dict[sup]\n",
    "        return '%s%s:%sD'%(mut[0], new_inf, new_sup)\n",
    "    else:\n",
    "        return mut\n",
    "\n",
    "\n",
    "## 解析 all_mutation & target_mutation 信息\n",
    "def parse_mutation_information(mutation):\n",
    "    '''\n",
    "    mutation = 'X0+Y179:180D.Y186:186M_C:A+Z196I_T'\n",
    "    # mutation = 'X0+Y0+Z0'\n",
    "    muts = parse_mutation_information(mutation)\n",
    "    '''\n",
    "    import re\n",
    "    mut_list = re.split('\\+|\\.', mutation)\n",
    "    mut_dict = {'X': [], 'Y': [], 'Z': []}\n",
    "    for mut in mut_list:\n",
    "        mut_dict[mut[0]].append(mut)\n",
    "    return mut_dict\n",
    "\n",
    "\n",
    "## 调整突变坐标的参考系：以 gRNASeq 为基\n",
    "def adjust_off_target_mutaion_reference_system(mutation):\n",
    "    '''\n",
    "    mutation = 'X164I_T+Y178I_C+Z0'\n",
    "    mutation = 'X164:164D+Y187I_G+Z199:199M_C:T'\n",
    "    mutation = 'X0+Y0+Z0'\n",
    "    adjust_off_target_mutaion_reference_system(mutation)\n",
    "    '''\n",
    "    ## 长序列与短序列对应字典\n",
    "    index_dict = {}\n",
    "    for i in range(20):\n",
    "        index_dict[125 + i] = -19 + i\n",
    "    for i in range(63):\n",
    "        index_dict[145 + i] = 1 + i\n",
    "    for i in range(20):\n",
    "        index_dict[208 + i] = 64 + i\n",
    "    ## 解析 all_mutation & target_mutation 信息\n",
    "    mut_dict = parse_mutation_information(mutation)\n",
    "    new_mut_dict = {'X': '', 'Y': '', 'Z': ''}\n",
    "    for label, mut_list in mut_dict.items():\n",
    "        a_list = []\n",
    "        for mut in mut_list:\n",
    "            new_mut = transformer_core(mut, index_dict)\n",
    "            a_list.append(new_mut)\n",
    "        a_list.sort(reverse=False)\n",
    "        new_mut_dict[label] = '.'.join(a_list)\n",
    "    new_list = []\n",
    "    for label in ['X', 'Y', 'Z']:\n",
    "        new_list.append(new_mut_dict[label])\n",
    "    return '+'.join(new_list)\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## up, core, down 区域内突变核苷酸总长度\n",
    "def region_mutation_length(mutation):\n",
    "    mut_list = mutation.split(\".\")\n",
    "    mut_length = 0\n",
    "    for mut in mut_list:\n",
    "        if 'M' in mut:\n",
    "            mut_length += len(mut.split(\":\")[-1])\n",
    "        elif 'I' in mut:\n",
    "            mut_length += len(mut.split(\"_\")[-1])\n",
    "        elif 'D' in mut:\n",
    "            inf, sup = int(mut.split(':')[0][1:]), int(mut.split(':')[-1][:-1])\n",
    "            delt_length = sup - inf + 1\n",
    "            mut_length += delt_length\n",
    "        else:\n",
    "            pass\n",
    "    return mut_length\n",
    "\n",
    "\n",
    "def mutation_region_splitting(data):\n",
    "    ## step 1: mutaion 区域划分\n",
    "    data['new_mutation'] = data['all_mutation'].apply(lambda x: adjust_off_target_mutaion_reference_system(x))\n",
    "    ## up, core, down 区域内突变类型\n",
    "    data['up_mutation'] = data['new_mutation'].apply(lambda x: x.split('+')[0])\n",
    "    data['core_mutation'] = data['new_mutation'].apply(lambda x: x.split('+')[1])\n",
    "    data['down_mutation'] = data['new_mutation'].apply(lambda x: x.split('+')[2])\n",
    "    ## up, core, down 区域内间断突变的个数\n",
    "    data['up_mut_num'] = data['up_mutation'].apply(lambda x: len(x.split('.')) if x != 'X0' else 0)\n",
    "    data['core_mut_num'] = data['core_mutation'].apply(lambda x: len(x.split('.')) if x != 'Y0' else 0)\n",
    "    data['down_mut_num'] = data['down_mutation'].apply(lambda x: len(x.split('.')) if x != 'Z0' else 0)\n",
    "    ## up, core, down 区域内突变核苷酸总长度\n",
    "    data['up_mut_length'] = data['up_mutation'].apply(lambda x: region_mutation_length(x))\n",
    "    data['core_mut_length'] = data['core_mutation'].apply(lambda x: region_mutation_length(x))\n",
    "    data['down_mut_length'] = data['down_mutation'].apply(lambda x: region_mutation_length(x))\n",
    "    ############################################################\n",
    "    print(\"\\nFirst: 统计 X0+Y0+Z0、XA+Y0+Z0、X0+YA+Z0、X0+Y0+ZA、XA+YA+Z0、XA+Y0+ZA、X0+YA+ZA、XA+YA+ZA 的类型占比\")\n",
    "    data_000 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']==0) & (data['down_mut_num']==0), :]\n",
    "    data_100 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']==0) & (data['down_mut_num']==0), :]\n",
    "    data_010 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']!=0) & (data['down_mut_num']==0), :]\n",
    "    data_001 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']==0) & (data['down_mut_num']!=0), :]\n",
    "    data_110 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']!=0) & (data['down_mut_num']==0), :]\n",
    "    data_101 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']==0) & (data['down_mut_num']!=0), :]\n",
    "    data_011 = data.loc[(data['up_mut_num']==0) & (data['core_mut_num']!=0) & (data['down_mut_num']!=0), :]\n",
    "    data_111 = data.loc[(data['up_mut_num']!=0) & (data['core_mut_num']!=0) & (data['down_mut_num']!=0), :]\n",
    "    ## count\n",
    "    count_dict = {}\n",
    "    count_000 = data_000.shape[0]\n",
    "    count_100, count_010, count_001 = data_100.shape[0], data_010.shape[0], data_001.shape[0]\n",
    "    count_110, count_101, count_011 = data_110.shape[0], data_101.shape[0], data_011.shape[0]\n",
    "    count_111 = data_111.shape[0]\n",
    "    count_dict['X0+Y0+Z0'] = count_000\n",
    "    count_dict['XA+Y0+Z0'] = count_100\n",
    "    count_dict['X0+YA+Z0'] = count_010\n",
    "    count_dict['X0+Y0+ZA'] = count_001\n",
    "    count_dict['XA+YA+Z0'] = count_110\n",
    "    count_dict['XA+Y0+ZA'] = count_101\n",
    "    count_dict['X0+YA+ZA'] = count_011\n",
    "    count_dict['XA+YA+ZA'] = count_111\n",
    "    print(\"X0+Y0+Z0:\", count_000)\n",
    "    print(\"XA+Y0+Z0:\", count_100)\n",
    "    print(\"X0+YA+Z0:\", count_010)\n",
    "    print(\"X0+Y0+ZA:\", count_001)\n",
    "    print(\"XA+YA+Z0:\", count_110)\n",
    "    print(\"XA+Y0+ZA:\", count_101)\n",
    "    print(\"X0+YA+ZA:\", count_011)\n",
    "    print(\"XA+YA+ZA:\", count_111)\n",
    "    count_sum = data.shape[0]\n",
    "    print(\"Distribution of count ratio:\", round(count_000/count_sum, 3), \n",
    "                        round(count_100/count_sum, 3), round(count_010/count_sum, 3), round(count_001/count_sum, 3), \n",
    "                        round(count_110/count_sum, 3), round(count_101/count_sum, 3), round(count_011/count_sum, 3), \n",
    "                        round(count_111/count_sum, 3))\n",
    "    return (data_000, data_100, data_010, data_001, data_110, data_101, data_011, data_111, count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get deletion off-target data & on-target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get deletion off-target data & on-target data\n",
    "def get_deletion_and_on_target_data(data_dir, mut_type, reads_num, barcode_num):\n",
    "    delt_path = data_dir + '/off-target.%s.accurate.offseq'%(mut_type)\n",
    "    delt = pd.read_csv(delt_path, sep='\\t')\n",
    "    delt = delt.loc[(delt['reads_num']>=reads_num) & (delt['barcode_num']>=barcode_num), :]\n",
    "    delt.reset_index(drop=True, inplace=True)\n",
    "    print(delt.shape)\n",
    "    ## data 根据 up, core, down 区域突变与否划分数据集\n",
    "    delt_000, delt_100, delt_010, delt_001, delt_110, delt_101, delt_011, delt_111, count_dict = mutation_region_splitting(delt)\n",
    "    return (delt, delt_000, delt_100, delt_010, delt_001, delt_110, delt_101, delt_011, delt_111)\n",
    "\n",
    "\n",
    "## get on-target data\n",
    "def get_on_target_data(data_dir, reads_num, barcode_num):\n",
    "    ######################################\n",
    "    ## perfect\n",
    "    data_path = data_dir + '/off-target.perfect.accurate.offseq'\n",
    "    ## read\n",
    "    data = pd.read_csv(data_path, sep='\\t')\n",
    "    data = data.loc[(data['reads_num']>=reads_num) & (data['barcode_num']>=barcode_num), :]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    print(data.shape)\n",
    "    ## data 根据 up, core, down 区域突变与否划分数据集\n",
    "    data_000, data_100, data_010, data_001, data_110, data_101, data_011, data_111, count_dict = mutation_region_splitting(data)\n",
    "    return (data, data_000, data_100, data_010, data_001, data_110, data_101, data_011, data_111)\n",
    "\n",
    "\n",
    "## for matching off-target deletion with on-target data \n",
    "def Obtain_deletion_data(delt, data, delt_010, delt_110, delt_111, delt_011, \n",
    "                         data_000, data_100, data_101, data_001, save_dir): \n",
    "    ## 确定 deletion id\n",
    "    ## 1、deletion X0+YA+Z0\n",
    "    print(\"\\n1、deletion X0+YA+Z0 \")\n",
    "    delt_id_1 = delt_010[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    on_id_1 = data_000[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    comm_id_1 = pd.merge(delt_id_1, on_id_1, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    print(\"X0+YA+Z0 deletion id:\", delt_id_1.shape)\n",
    "    print(\"X0+Y0+Z0 perfect id:\", on_id_1.shape)\n",
    "    print(\"common X0+YA+Z0 & perfect id\", comm_id_1.shape)\n",
    "\n",
    "    ## 2、deletion XA+YA+Z0\n",
    "    print(\"\\n2、deletion XA+YA+Z0 \")\n",
    "    delt_id_2 = delt_110[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    on_id_2 = data_100[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    comm_id_2 = pd.merge(delt_id_2, on_id_2, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    print(\"XA+YA+Z0 deletion id:\", delt_id_2.shape)\n",
    "    print(\"XA+Y0+Z0 perfect id:\", on_id_2.shape)\n",
    "    print(\"common XA+YA+Z0 & perfect id:\", comm_id_2.shape)\n",
    "\n",
    "    ## 3、deletion XA+YA+ZA\n",
    "    print(\"\\n3、insertion XA+YA+ZA\")\n",
    "    delt_id_3 = delt_111[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    on_id_3 = data_101[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    comm_id_3 = pd.merge(delt_id_3, on_id_3, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    print(\"XA+YA+ZA deletion id:\", delt_id_3.shape)\n",
    "    print(\"XA+Y0+ZA perfect id:\", on_id_3.shape)\n",
    "    print(\"common XA+YA+ZA & perfect id:\", comm_id_3.shape)\n",
    "\n",
    "    ## 4、deletion X0+YA+ZA\n",
    "    print(\"\\n4、deletion X0+YA+ZA \")\n",
    "    delt_id_4 = delt_011[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    on_id_4 = data_001[['sgRNA_name', 'up_mutation', 'down_mutation']].drop_duplicates()\n",
    "    comm_id_4 = pd.merge(delt_id_4, on_id_4, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    print(\"X0+YA+ZA deletion id:\", delt_id_4.shape)\n",
    "    print(\"X0+Y0+ZA perfect id:\", on_id_4.shape)\n",
    "    print(\"common X0+YA+ZA & perfect id:\", comm_id_4.shape)\n",
    "\n",
    "    ## merging \n",
    "    print(\"\\nmerging\")\n",
    "    comm_id = pd.concat([comm_id_1, comm_id_2, comm_id_3, comm_id_4], axis=0)\n",
    "    ## For perfect\n",
    "    on_id = pd.merge(data[['sgRNA_name', 'up_mutation', 'down_mutation', 'reads_num', 'barcode_num', 'off-target_eff']], \n",
    "                     comm_id, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    on_id.rename(columns={'reads_num': 'p_reads_num', 'barcode_num': 'p_barcode_num', 'off-target_eff': 'on-target_eff'}, \n",
    "                 inplace=True)\n",
    "    print(\"perfect on_id:\", on_id.shape)\n",
    "    delt_id = pd.merge(delt, on_id, how='inner', on=['sgRNA_name', 'up_mutation', 'down_mutation'])\n",
    "    ## 可用于分析的\n",
    "    delt1 = delt_id.loc[(delt_id['up_mut_num']==0) & (delt_id['core_mut_num']!=0) & (delt_id['down_mut_num']==0), :]\n",
    "    delt2 = delt_id.loc[(delt_id['up_mut_num']!=0) & (delt_id['core_mut_num']!=0) & (delt_id['down_mut_num']==0), :]\n",
    "    delt3 = delt_id.loc[(delt_id['up_mut_num']!=0) & (delt_id['core_mut_num']!=0) & (delt_id['down_mut_num']!=0), :]\n",
    "    delt4 = delt_id.loc[(delt_id['up_mut_num']==0) & (delt_id['core_mut_num']!=0) & (delt_id['down_mut_num']!=0), :]\n",
    "    print(\"\\nSum number - delt_id.shape:\", delt_id.shape)\n",
    "    print(\"X0+YA+Z0 delt1.shape:\", delt1.shape)\n",
    "    print(\"XA+YA+Z0 delt2.shape:\", delt2.shape)\n",
    "    print(\"XA+YA+ZA delt3.shape:\", delt3.shape)\n",
    "    print(\"X0+YA+ZA delt4.shape:\", delt4.shape)\n",
    "    ## to save\n",
    "    mkdir(save_dir)\n",
    "    delt_id.to_excel(save_dir + '/off-target deletion data.xlsx', index=False)\n",
    "    return (delt_id, delt1, delt2, delt3, delt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The distribution of deletion position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deletion position\n",
    "def deletion_position(mutation):\n",
    "    import re\n",
    "    mut_list = re.split('\\+|\\.', mutation)\n",
    "    positions = []\n",
    "    for mut in mut_list:\n",
    "        if \"D\" in mut:\n",
    "            inf , sup = int(mut.split(\":\")[0][1:]), int(mut.split(\":\")[1][:-1])\n",
    "            for pos in range(inf, sup+1, 1):\n",
    "                positions.append(pos)\n",
    "        else:\n",
    "            pass\n",
    "    return str(positions)\n",
    "\n",
    "\n",
    "### 合并所有的 delt\n",
    "def obtain_deletion_position_distribution(delt1, delt2, delt3, delt4, save_dir):\n",
    "    ## concat\n",
    "    delt_s = pd.concat([delt1, delt2, delt3, delt4], axis=0)\n",
    "    delt11 = delt_s.loc[(delt_s['core_mut_length']==1) & (delt_s['on-target_eff']>=0.05), :]\n",
    "    print(delt_s.shape, delt11.shape, len(list(delt11['sgRNA_name'].unique())))\n",
    "    delt11['position'] = delt11['core_mutation'].apply(lambda x: deletion_position(x))\n",
    "    delt11['position'] = delt11['position'].apply(lambda x: eval(x)[0])\n",
    "    delt11['reltv_eff'] = delt11.apply(lambda row: row['off-target_eff']/row['on-target_eff'], axis=1)\n",
    "    stat_eff_df = delt11[['position', 'off-target_eff', 'on-target_eff', 'reltv_eff']]\n",
    "    ## to save\n",
    "    stat_eff_df.to_excel(save_dir + '/deletion_distribution_analysis.xlsx', index=False)\n",
    "    ## deletion position distribution \n",
    "    stat_eff_df['count'] = 1\n",
    "    stat_df = stat_eff_df[['position', 'count']].groupby('position').sum()\n",
    "    stat_df.sort_values(by='position', ascending=True, inplace=True)\n",
    "    stat_df.reset_index(drop=False, inplace=True)\n",
    "    return stat_df, stat_eff_df\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 柱状图\n",
    "def get_xticks(stat_df):\n",
    "    ## labels \n",
    "    pam_dict = {41: 'N', 42: 'G', 43: 'G'}\n",
    "    pos_list = stat_df['position'].tolist()\n",
    "    xticks = []\n",
    "    for pos in pos_list:\n",
    "        if pos not in pam_dict:\n",
    "            xticks.append(pos-20)\n",
    "        else:\n",
    "            xticks.append(pam_dict[pos])\n",
    "    return xticks\n",
    "\n",
    "\n",
    "def plot_single_bar(data_list, xticks, title, save_dir, \n",
    "                    xlabel='Target+PAM Insertion Position', ylabel='Count'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # 设置默认绘图风格\n",
    "    plt.style.use(\"seaborn-white\")  \n",
    "    fig, ax = plt.subplots(1,1, figsize=(12, 4))\n",
    "\n",
    "    plt.bar(range(len(data_list)), data_list, color='lightseagreen')\n",
    "    ## 坐标轴不可见\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ## xlabel, ylabel\n",
    "    plt.xlabel(xlabel, fontsize=12, weight='bold')\n",
    "    plt.ylabel(ylabel, fontsize=12, weight='bold')\n",
    "    ## xticks\n",
    "    plt.xticks(range(len(xticks)), xticks, fontsize=12, weight='bold')\n",
    "    ## title\n",
    "    plt.title(title, fontsize=12, weight='bold')\n",
    "    ## save\n",
    "    mkdir(save_dir)\n",
    "    savefig_path = save_dir + '/%s.%s'%(title, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "## plot effect of deletion position on efficiency\n",
    "def plot_deletion_reltv_eff(stat_eff_df, save_dir):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # 设置默认绘图风格\n",
    "    plt.style.use(\"seaborn-white\")  \n",
    "    fig, ax = plt.subplots(1,1, figsize=(6, 3))\n",
    "#     fig, ax = plt.subplots(1,1, figsize=(12, 6))\n",
    "    \n",
    "    order = [(i) for i in range(21, 43)]\n",
    "    ax = sns.boxplot(x='position', y='reltv_eff', data=stat_eff_df, width=0.4, color='white', \n",
    "                     fliersize=0.5, linewidth=0.5, order=order)\n",
    "    ## 坐标轴不可见\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax = sns.stripplot(x='position', y='reltv_eff', data=stat_eff_df, \n",
    "                       color=\"orange\", jitter=0.1, size=0.8, order=order)\n",
    "    ## xlabel, ylabel\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    ## xticks\n",
    "    xticks = list(range(1, 21, 1)) + ['N', 'G']\n",
    "    plt.xticks(range(len(xticks)), xticks, fontsize=6, weight='bold')\n",
    "    plt.yticks(fontsize=6, weight='bold')\n",
    "    ## ylim\n",
    "    plt.xlim(-1, 22)\n",
    "    title = 'Effect of off-target deletion position on gRNA acitvity - D-1'\n",
    "    mkdir(save_dir)\n",
    "    savefig_path = save_dir + '/%s.%s'%(title, figsuplix)\n",
    "    plt.savefig(savefig_path, dpi=300, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def main_plot_off_target_deletion_effect(delt1, delt2, delt3, delt4, save_dir):\n",
    "    ## plot the distribution of deletion position\n",
    "    stat_df, stat_eff_df = obtain_deletion_position_distribution(delt1, delt2, delt3, delt4, save_dir)\n",
    "    xticks = get_xticks(stat_df)\n",
    "    data_list = stat_df['count'].tolist()\n",
    "    title = \"position distribution of off-target deletion - D-1\"\n",
    "    ylabel = 'off-target id count'\n",
    "    xlabel = 'Target+PAM Deletion Position'\n",
    "    plot_single_bar(data_list, xticks, title, save_dir, xlabel, ylabel)\n",
    "    ## plot distribution of relative efficiency of deletion\n",
    "    plot_deletion_reltv_eff(stat_eff_df, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
